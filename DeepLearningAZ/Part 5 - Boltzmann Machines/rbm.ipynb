{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO49tNBkSWs31OOVHFx7mqa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kqyu1kmoKbrE"},"source":["# Boltzmann Machines"]},{"cell_type":"markdown","metadata":{"id":"9tAA6MwdRAVd"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"rvT-kejMRJgi","executionInfo":{"status":"ok","timestamp":1727885831233,"user_tz":-240,"elapsed":5062,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDWL9xRfSRhC"},"source":["## Importing the dataset"]},{"cell_type":"code","metadata":{"id":"-TUs9ZhVXoS8","executionInfo":{"status":"ok","timestamp":1727885843308,"user_tz":-240,"elapsed":7370,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ifo6XYFvXsRF"},"source":["## Preparing the training set and the test set"]},{"cell_type":"code","metadata":{"id":"_9ctYDUSX5BW","executionInfo":{"status":"ok","timestamp":1727885848024,"user_tz":-240,"elapsed":611,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ujNEtV_fX8d3"},"source":["## Getting the number of users and movies"]},{"cell_type":"code","metadata":{"id":"PtCZ9njUYABx","executionInfo":{"status":"ok","timestamp":1727885850487,"user_tz":-240,"elapsed":420,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n","nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPJDmiQlYD1r"},"source":["## Converting the data into an array with users in lines and movies in columns"]},{"cell_type":"code","metadata":{"id":"fj8m4cOtYUFR","executionInfo":{"status":"ok","timestamp":1727885853520,"user_tz":-240,"elapsed":1181,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["def convert(data):\n","    new_data = []\n","    for id_users in range(1, nb_users + 1):\n","        id_movies = data[:,1][data[:,0] == id_users]\n","        id_ratings = data[:,2][data[:,0] == id_users]\n","        ratings = np.zeros(nb_movies)\n","        ratings[id_movies - 1] = id_ratings\n","        new_data.append(list(ratings))\n","    return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aj4327VkYZAB"},"source":["## Converting the data into Torch tensors"]},{"cell_type":"code","metadata":{"id":"2dApDXxNYduB","executionInfo":{"status":"ok","timestamp":1727885856987,"user_tz":-240,"elapsed":365,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5n17yuE5YheZ"},"source":["## Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)"]},{"cell_type":"code","metadata":{"id":"98UFbH1bYpkA","executionInfo":{"status":"ok","timestamp":1727885859491,"user_tz":-240,"elapsed":535,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"source":["training_set[training_set == 0] = -1\n","training_set[training_set == 1] = 0\n","training_set[training_set == 2] = 0\n","training_set[training_set >= 3] = 1\n","test_set[test_set == 0] = -1\n","test_set[test_set == 1] = 0\n","test_set[test_set == 2] = 0\n","test_set[test_set >= 3] = 1"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVXY7u7NYuuC"},"source":["## Creating the architecture of the Neural Network"]},{"cell_type":"code","source":["class RBM():\n","    def __init__(self, nv, nh):\n","        self.W = torch.randn(nh, nv)\n","        self.a = torch.randn(1, nh)\n","        self.b = torch.randn(1, nv)\n","    def sample_h(self, x):\n","        wx = torch.mm(x, self.W.t())\n","        activation = wx + self.a.expand_as(wx)\n","        p_h_given_v = torch.sigmoid(activation)\n","        return p_h_given_v, torch.bernoulli(p_h_given_v)\n","    def sample_v(self, y):\n","        wy = torch.mm(y, self.W)\n","        activation = wy + self.b.expand_as(wy)\n","        p_v_given_h = torch.sigmoid(activation)\n","        return p_v_given_h, torch.bernoulli(p_v_given_h)\n","    def train(self, v0, vk, ph0, phk):\n","        self.W += torch.mm(v0.t(), ph0).t() - torch.mm(vk.t(), phk).t()\n","        self.b += torch.sum((v0 - vk), 0)\n","        self.a += torch.sum((ph0 - phk), 0)\n","nv = len(training_set[0])\n","nh = 100\n","batch_size = 100\n","rbm = RBM(nv, nh)"],"metadata":{"id":"z-VRVwOw__D0","executionInfo":{"status":"ok","timestamp":1727885871375,"user_tz":-240,"elapsed":495,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JXT6ofIOY61G"},"source":["## Training the RBM"]},{"cell_type":"code","metadata":{"id":"dBpiBfDZY-le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727885901309,"user_tz":-240,"elapsed":11737,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}},"outputId":"659dbc75-4a15-4b67-e505-f1ece3ef1c84"},"source":["nb_epoch = 10\n","for epoch in range(1, nb_epoch + 1):\n","    train_loss = 0\n","    s = 0.\n","    for id_user in range(0, nb_users - batch_size, batch_size):\n","        vk = training_set[id_user:id_user+batch_size]\n","        v0 = training_set[id_user:id_user+batch_size]\n","        ph0,_ = rbm.sample_h(v0)\n","        for k in range(10):\n","            _,hk = rbm.sample_h(vk)\n","            _,vk = rbm.sample_v(hk)\n","            vk[v0<0] = v0[v0<0]\n","        phk,_ = rbm.sample_h(vk)\n","        rbm.train(v0, vk, ph0, phk)\n","        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n","        s += 1.\n","    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1 loss: tensor(0.3432)\n","epoch: 2 loss: tensor(0.2414)\n","epoch: 3 loss: tensor(0.2480)\n","epoch: 4 loss: tensor(0.2485)\n","epoch: 5 loss: tensor(0.2471)\n","epoch: 6 loss: tensor(0.2487)\n","epoch: 7 loss: tensor(0.2485)\n","epoch: 8 loss: tensor(0.2463)\n","epoch: 9 loss: tensor(0.2457)\n","epoch: 10 loss: tensor(0.2475)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dcksm8T5ZCpo"},"source":["## Testing the RBM"]},{"cell_type":"code","metadata":{"id":"iAVLhcHsZGIA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727885386828,"user_tz":-240,"elapsed":28,"user":{"displayName":"Hadelin de Ponteves","userId":"15047218817161520419"}},"outputId":"2da606ff-d3f8-4e51-a0ce-ff57579fb053"},"source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","    v = training_set[id_user:id_user+1]\n","    vt = test_set[id_user:id_user+1]\n","    if len(vt[vt>=0]) > 0:\n","        _,h = rbm.sample_h(v)\n","        _,v = rbm.sample_v(h)\n","        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n","        s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["test loss: tensor(0.2265)\n"]}]}]}